{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb3849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.plotDecBoundaries import plotDecBoundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baa029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(fname):\n",
    "    with open(fname, mode ='r')as file:\n",
    "        # reading the CSV file\n",
    "        csvFile = csv.reader(file)\n",
    "        \n",
    "        # create a new array to store the data\n",
    "        dataA = np.empty([0,2])\n",
    "        dataB = np.empty([0,2])\n",
    "        labels = np.empty([0,1])\n",
    "\n",
    "        # displaying the contents of the CSV file\n",
    "        for lines in csvFile:\n",
    "            if(float(lines[2]) == 1.):\n",
    "                dataA = np.row_stack((dataA,[float(lines[0]), float(lines[1])]))\n",
    "            else:\n",
    "                dataB = np.row_stack((dataB,[float(lines[0]), float(lines[1])]))\n",
    "        \n",
    "    N1 = len(dataA)\n",
    "    N2 = len(dataB)\n",
    "    labels = np.ones( N1 + N2 )\n",
    "    labels[N1:] += 1\n",
    "    \n",
    "    return (dataA, dataB, labels, N1, N2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3754a6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_means_classifier(fname):\n",
    "    (dataA,dataB,labels,N1,N2) = getData(fname)\n",
    "    \n",
    "    N = N1 + N2\n",
    "    data = np.row_stack((dataA,dataB))\n",
    "\n",
    "    sample_means = np.zeros((2,2))\n",
    "    sample_means[0] = np.mean(data[:N1], axis=0)\n",
    "    sample_means[1] = np.mean(data[N1:], axis=0)\n",
    "    \n",
    "\n",
    "    print(f'{N} total data points.  {N1} in class 1 and {N2} in class 2\\n')\n",
    "\n",
    "    print(f'The sample mean for class 1 data is: {sample_means[0]}\\n')\n",
    "\n",
    "    print(f'The sample mean for class 2 data is: {sample_means[1]}')\n",
    "\n",
    "    plotDecBoundaries(data, labels, sample_means, fsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a77b41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test(fname, means):\n",
    "    (dataA,dataB,labels,N1,N2) = getData(fname)\n",
    "    \n",
    "    N = N1 + N2\n",
    "    data = np.row_stack((dataA,dataB))\n",
    "\n",
    "    N1_errors = 0\n",
    "    N2_errors = 0\n",
    "    i = 0\n",
    "    for ele in data:\n",
    "        dis_mean1 = np.square((ele[0] - means[0][0])**2 + (ele[1] - means[0][1]) ** 2)\n",
    "        dis_mean2 = np.square((ele[0] - means[1][0])**2 + (ele[1] - means[1][1]) ** 2)\n",
    "        if(dis_mean1 < dis_mean2 and labels[i] == 2.):\n",
    "            N1_errors += 1\n",
    "        elif(dis_mean1 > dis_mean2 and labels[i] == 1.):\n",
    "            N2_errors += 1\n",
    "        i += 1\n",
    "        \n",
    "    error_rate =( N1_errors + N2_errors ) / 100 * 100\n",
    "    print(f'Error rate = {error_rate : 0.3f}%')\n",
    "\n",
    "    sample_means = np.zeros((2,2))\n",
    "    sample_means[0] = means[0]\n",
    "    sample_means[1] = means[1]\n",
    "\n",
    "    plotDecBoundaries(data, labels, sample_means, fsize=(10,10))\n",
    "    \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd318f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_means_classifier('dataset1_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a687cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_test('dataset1_train.csv',[[0.08893115, 1.08956606],[1.04128622 ,0.01994688]])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ad417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_test('dataset1_test.csv',[[0.08893115,1.08956606],[1.04128622,0.01994688]])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc71a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_means_classifier('dataset2_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cbb878",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_test('dataset2_train.csv',[[-0.3536011,0.99036239],[1.03652797,-0.03223129]])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c712fa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_test('dataset2_test.csv',[[-0.3536011,0.99036239],[1.03652797,-0.03223129]])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343a45a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_means_classifier('dataset3_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253311ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_test('dataset3_train.csv',[[-0.06738853 , 0.21324203],[ 0.52230078 , 0.93267215]])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d31b4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_test('dataset3_test.csv',[[-0.06738853 , 0.21324203],[ 0.52230078 , 0.93267215]])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2f4be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data):\n",
    "    # caculate the standard deviation and the mean\n",
    "    total_means = np.mean(data[:], axis=0)\n",
    "    print(f'The total mean for class 1&2 data is: {total_means}\\n')\n",
    "    \n",
    "    total_stds = np.std(data[:], axis=0)\n",
    "    print(f'The total std for class 1&2 data is: {total_stds}\\n')\n",
    "    \n",
    "    # normalize the data\n",
    "    data = (data[:] - total_means) / total_stds\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44e51f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data_mean(data, total_means, total_stds):\n",
    "    # normalize the data\n",
    "    data = (data[:] - total_means) / total_stds\n",
    "    \n",
    "    total_means_after = np.mean(data[:], axis=0)\n",
    "    print(f'The total mean for class 1&2 data is: {total_means_after}\\n')\n",
    "    total_stds_after = np.std(data[:], axis=0)\n",
    "    print(f'The total std for class 1&2 data is: {total_stds_after}\\n')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fecb882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_mean_classifier_standardize(fname):\n",
    "    (dataA,dataB,labels,N1,N2) = getData(fname)\n",
    "    \n",
    "    N = N1 + N2\n",
    "    data = np.row_stack((dataA,dataB))\n",
    "    \n",
    "    data = normalize_data(data)\n",
    "    \n",
    "    \n",
    "    sample_means = np.zeros((2,2))\n",
    "    sample_means[0] = np.mean(data[:N1], axis=0)\n",
    "    sample_means[1] = np.mean(data[N1:], axis=0)\n",
    "    print(f'The sample mean for class 1 data is: {sample_means[0]}\\n')\n",
    "    print(f'The sample mean for class 2 data is: {sample_means[1]}\\n')\n",
    "    \n",
    "    total_means = np.mean(data[:], axis=0)\n",
    "    print(f'The total mean for data is: {total_means}\\n')\n",
    "    total_stds = np.std(data[:], axis=0)\n",
    "    print(f'The total std for class 1&2 data is: {total_stds}\\n')\n",
    "    \n",
    "    \n",
    "    plotDecBoundaries(data, labels, sample_means, fsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211bf7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_standard_test(fname, total_means, means, total_stds):\n",
    "    \n",
    "    (dataA,dataB,labels,N1,N2) = getData(fname)\n",
    "    \n",
    "    N = N1 + N2\n",
    "    data = np.row_stack((dataA,dataB))\n",
    "    \n",
    "    # normalize the data\n",
    "    data = normalize_data_mean(data, total_means, total_stds)\n",
    "    \n",
    "    N1_errors = 0\n",
    "    N2_errors = 0\n",
    "    i = 0\n",
    "\n",
    "    for ele in data:\n",
    "        dis_mean1 = np.square((float(ele[0]) - means[0][0])**2 + (float(ele[1]) - means[0][1]) ** 2)\n",
    "        dis_mean2 = np.square((float(ele[0]) - means[1][0])**2 + (float(ele[1]) - means[1][1]) ** 2)\n",
    "        if(dis_mean1 < dis_mean2 and labels[i] == 2.):\n",
    "            N1_errors += 1\n",
    "        elif(dis_mean1 > dis_mean2 and labels[i] == 1.):\n",
    "            N2_errors += 1\n",
    "        i += 1\n",
    "    error_rate =( N1_errors + N2_errors ) / 100 * 100\n",
    "    \n",
    "    print(f'Error rate = {error_rate : 0.3f}%')\n",
    "    \n",
    "    sample_means = np.zeros((2,2))\n",
    "    sample_means[0] = means[0]\n",
    "    sample_means[1] = means[1]\n",
    "    plotDecBoundaries(data, labels, sample_means, fsize=(10,10))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf69ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_mean_classifier_standardize('dataset1_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178d7c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_standard_test('dataset1_train.csv', [0.56510868, 0.55475647],\n",
    "                       [[-0.40664534,0.45213344],[ 0.40664534, -0.45213344]] , [1.17098977,1.18285787])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6b136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_standard_test('dataset1_test.csv', [0.56510868, 0.55475647], \n",
    "                       [[-0.40664534,0.45213344],[ 0.40664534, -0.45213344]] , [1.17098977,1.18285787])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa49db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_mean_classifier_standardize('dataset2_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a19d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_standard_test('dataset2_train.csv', [0.34146344,0.47906555], \n",
    "                       [[-0.53490724,0.95882365],[0.53490724,-0.95882365]] , [1.29941135,0.53325431])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0823981",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classify_standard_test('dataset2_test.csv', [0.34146344,0.47906555], \n",
    "                       [[-0.53490724,0.95882365],[0.53490724,-0.95882365]] , [1.29941135,0.53325431])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29889f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_mean_classifier_standardize('dataset3_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6072dc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_standard_test('dataset3_train.csv', [0.22745613,0.57295709], \n",
    "                       [[-0.2061046,-0.30508577],[0.2061046,0.30508577]] , [1.43055836,1.17906206])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d8cd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_standard_test('dataset3_test.csv', [0.22745613,0.57295709], \n",
    "                       [[-0.2061046,-0.30508577],[0.2061046,0.30508577]] , [1.43055836,1.17906206])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f086cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_error_rate(data, N1, N2, labels, sample_means):\n",
    "    \n",
    "    N1_errors = 0\n",
    "    N2_errors = 0\n",
    "    i = 0\n",
    "    \n",
    "    for ele in data:\n",
    "        dis_mean1 = abs(ele - sample_means[0])\n",
    "        dis_mean2 = abs(ele - sample_means[1])\n",
    "        if(dis_mean1 < dis_mean2 and labels[i] == 2.):\n",
    "            N1_errors += 1\n",
    "        elif(dis_mean1 > dis_mean2 and labels[i] == 1.):\n",
    "            N2_errors += 1\n",
    "        i += 1\n",
    "    error_rate =( N1_errors + N2_errors ) / 100 * 100\n",
    "    \n",
    "#     print(f'Error rate = {error_rate : 0.3f}%')\n",
    "    return error_rate\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d816f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def projector(fname):\n",
    "    (dataA,dataB,labels,N1,N2) = getData(fname)\n",
    "    \n",
    "    N = N1 + N2\n",
    "    data = np.row_stack((dataA,dataB))\n",
    "    \n",
    "    # caculate the standard deviation and the mean\n",
    "    total_means = np.mean(data[:], axis=0)\n",
    "    total_stds = np.std(data[:], axis=0)\n",
    "    \n",
    "    # normalize the data\n",
    "    data = (data[:] - total_means) / total_stds\n",
    "        \n",
    "    # find the min m\n",
    "    rm_star = []\n",
    "    m_star = 100\n",
    "    errorRate = 100.\n",
    "    train_mean = []\n",
    "    \n",
    "    x = []\n",
    "    e = []\n",
    "#     x = np.empty(40)\n",
    "#     e = np.empty(40)\n",
    "    \n",
    "    for m in range(10):\n",
    "        rm = [10, m ]\n",
    "        rmUnit = rm / np.linalg.norm(rm)\n",
    "        dotdata = np.dot(data,rm)\n",
    "        \n",
    "        sample_means = np.zeros(2)\n",
    "        sample_means[0] = np.mean(dotdata[:N1])\n",
    "        sample_means[1] = np.mean(dotdata[N1:])\n",
    "        error_rate_this = float(caculate_error_rate(dotdata, N1, N2, labels, sample_means))\n",
    "#         np.row_stack((e,error_rate_this))\n",
    "        e.append(error_rate_this)\n",
    "        x.append(m)\n",
    "#         e = np.row_stack((e,error_rate_this))\n",
    "#         x = np.row_stack((x,m))\n",
    "#         e = np.append(e, [error_rate_this], axis=0)\n",
    "#         x =np.append(x,[m],axis = 0)\n",
    "    \n",
    "        if error_rate_this < errorRate:\n",
    "            errorRate = error_rate_this\n",
    "            m_star = m\n",
    "            rm_star = rm\n",
    "            train_mean = sample_means\n",
    "        print('m = ', m, ',rm = ', rm, f',errorRate = { error_rate_this : 0.3f}%' )\n",
    "        \n",
    "    for m in range(10,30):\n",
    "        rm = [20 - m, 10]\n",
    "        rmUnit = rm / np.linalg.norm(rm)\n",
    "        dotdata = np.dot(data,rm)\n",
    "        \n",
    "        sample_means = np.zeros(2)\n",
    "        sample_means[0] = np.mean(dotdata[:N1])\n",
    "        sample_means[1] = np.mean(dotdata[N1:])\n",
    "        error_rate_this = float(caculate_error_rate(dotdata, N1, N2, labels, sample_means))\n",
    "#         np.row_stack((e,error_rate_this))\n",
    "        e.append(error_rate_this)\n",
    "        x.append(m)\n",
    "#         e = np.append(e, [error_rate_this], axis=0)\n",
    "#         x = np.append(x,[m],axis = 0)\n",
    "    \n",
    "\n",
    "\n",
    "        if error_rate_this < errorRate:\n",
    "            errorRate = error_rate_this\n",
    "            m_star = m\n",
    "            rm_star = rm\n",
    "            train_mean = sample_means\n",
    "        print('m = ', m, ',rm = ', rm, f',errorRate = { error_rate_this : 0.3f}%')\n",
    "        \n",
    "    for m in range(30,40):\n",
    "        rm = [-10, 40-m]\n",
    "        rmUnit = rm / np.linalg.norm(rm)\n",
    "        dotdata = np.dot(data,rm)\n",
    "        \n",
    "        sample_means = np.zeros(2)\n",
    "        sample_means[0] = np.mean(dotdata[:N1])\n",
    "        sample_means[1] = np.mean(dotdata[N1:])\n",
    "        \n",
    "        error_rate_this = float(caculate_error_rate(dotdata, N1, N2, labels, sample_means))\n",
    "#         np.row_stack((e,error_rate_this))\n",
    "        e.append(error_rate_this)\n",
    "        x.append(m)\n",
    "#         e = np.append(e, [error_rate_this], axis=0)\n",
    "#         x = np.append(x,[m],axis = 0)\n",
    "\n",
    "        if error_rate_this < errorRate:\n",
    "            errorRate = error_rate_this\n",
    "            m_star = m\n",
    "            rm_star = rm\n",
    "            train_mean = sample_means\n",
    "        print('m = ', m, ',rm = ', rm, f',errorRate = { error_rate_this : 0.3f}%')\n",
    "    \n",
    "    plt.plot(x,e)\n",
    "    plt.show()\n",
    "    \n",
    "    rmUnit = rm_star / np.linalg.norm(rm_star)\n",
    "    dotdata = np.dot(data,rm_star)\n",
    "    \n",
    "    dataUnit = np.empty([0,2])\n",
    "    for e in dotdata:\n",
    "        dataUnit = np.row_stack((dataUnit, e * rmUnit))\n",
    "#     print(dataUnit)\n",
    "    \n",
    "#     print(np.mean(dotdata))\n",
    "    sample_means = np.zeros((2,2))\n",
    "    sample_means[0] = np.mean(dataUnit[:N1], axis=0)\n",
    "    sample_means[1] = np.mean(dataUnit[N1:], axis=0)\n",
    "    \n",
    "    print('m* = ',m_star,f', errorRate = { errorRate: 0.3f}%, rm* = ',rm_star,', means = ',sample_means, 'train means = ',train_mean)\n",
    "    plotDecBoundaries(dataUnit, labels, sample_means, fsize=(10,10))\n",
    "    \n",
    "\n",
    "#     print(sample_means)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6e0eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_project_test(fname, total_means, means, total_stds, rm, sample_means):\n",
    "    (dataA,dataB,labels,N1,N2) = getData(fname)\n",
    "     \n",
    "    N = N1 + N2\n",
    "    data = np.row_stack((dataA,dataB))\n",
    "    \n",
    "    # normalize the data\n",
    "    data = (data[:] - total_means) / total_stds\n",
    "    \n",
    "    # dataUnit = np.dot(data,rm) / np.dot(rm,rm) * rm\n",
    "    rmUnit = rm / np.linalg.norm(rm)\n",
    "    dotdata = np.dot(data,rm)\n",
    "    dataUnit = np.empty([0,2])\n",
    "    for e in dotdata:\n",
    "        dataUnit = np.row_stack((dataUnit, e * rmUnit))\n",
    "    \n",
    "    N1_errors = 0\n",
    "    N2_errors = 0\n",
    "    i = 0\n",
    "    \n",
    "    error_rate = float(caculate_error_rate(dotdata, N1, N2, labels, sample_means))\n",
    "    print(f'Error rate = {error_rate : 0.3f}%')\n",
    "    \n",
    "    sm = np.zeros((2,2))\n",
    "    sm[0] = means[0]\n",
    "    sm[1] = means[1]\n",
    "    \n",
    "    plotDecBoundaries(dataUnit, labels, sm, fsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d9eff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "projector('dataset1_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81da438",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_project_test('dataset1_test.csv', [0.56510868, 0.55475647], [[-4.22518553,6.03597933],\n",
    "[ 4.22518553,-6.03597933]] , [1.17098977,1.18285787], [-7,10], [ 7.36785174 , -7.36785174])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43151377",
   "metadata": {},
   "outputs": [],
   "source": [
    "projector('dataset2_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6274d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_project_test('dataset2_test.csv', [0.34146344,0.47906555], [[ 1.67060001,8.35300006],\n",
    " [-1.67060001, -8.35300006]] , [1.29941135,0.53325431],[2,10],[ 8.51842206, -8.51842206])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ce3749",
   "metadata": {},
   "outputs": [],
   "source": [
    "projector('dataset3_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa5ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_project_test('dataset3_test.csv', [0.22745613,0.57295709], [[-3.51526224,-2.81220979],\n",
    " [ 3.51526224,2.81220979]] , [1.43055836,1.17906206],[10,8],[-4.50173217 , 4.50173217])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
